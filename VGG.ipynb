{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "import pickle\n",
    "import torchvision.models as models\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class DatasetClass(Dataset):\n",
    "    \n",
    "    def __init__(self, directory, img_size):\n",
    "        \n",
    "        self.directory = directory\n",
    "        self.classes = ['026.Bronzed_Cowbird',\t'084.Red_legged_Kittiwake',\t'131.Vesper_Sparrow',\t'085.Horned_Lark',\t'015.Lazuli_Bunting',\t'041.Scissor_tailed_Flycatcher',\t'114.Black_throated_Sparrow']\n",
    "        print('Number of Classes =', len(self.classes))\n",
    "        self.files = []\n",
    "        for class_name in self.classes:\n",
    "            images = os.listdir(directory + '/' + class_name)\n",
    "            images = [class_name + '/' + image for image in images]\n",
    "            self.files.extend(images)\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.size = len(self.files)\n",
    "        \n",
    "    def __getitem__(self, idx):     \n",
    "        \n",
    "        image_name = self.files[idx]\n",
    "        y = self.classes.index(re.split('/', image_name)[0])\n",
    "        img = Image.open(self.directory + '/' + image_name).convert(mode='RGB').resize(self.img_size)\n",
    "        \n",
    "        trans = transforms.ToTensor()\n",
    "        # return trans(img), torch.Tensor(y, dtype=torch.long)\n",
    "        \n",
    "        return trans(img), y        # Multiplying by pixel value\n",
    "      \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.size\n",
    "\n",
    "def train_test_loader(directory, img_size, train_fraction=0.7, cv_fraction=0.2, num_workers=0, batch_size=32):\n",
    "\n",
    "    dataset = DatasetClass(directory, img_size)\n",
    "    \n",
    "    N = dataset.size\n",
    "    train_size = int(N*train_fraction)\n",
    "    cv_size = int(N*cv_fraction)\n",
    "    test_size = N - train_size - cv_size\n",
    "\n",
    "    train_data, cv_data, test_data = torch.utils.data.random_split(dataset, [train_size, cv_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    cvloader = DataLoader(cv_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    return trainloader, cvloader, testloader, train_size, cv_size, test_size\n",
    "\n",
    "trainloader, cvloader, testloader, train_size, cv_size, test_size = train_test_loader('/content/drive/My Drive/Assignment3_Data/CUB_200_2011/images', (224, 224), batch_size=32)\n",
    "RGB_mean = torch.zeros(3)\n",
    "i = 0\n",
    "for X, y in trainloader:\n",
    "    i += 1\n",
    "    RGB_mean += (X.sum(0).sum(1).sum(1)/(X.shape[2]*X.shape[2]))/train_size\n",
    "    print(i, '/', len(trainloader), end=', ')\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, RGB_mean, num_classes):\n",
    "        super(VGGNet, self).__init__()\n",
    "        \n",
    "        self.RGB_mean = RGB_mean.to(device)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.c11 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.c12 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.p1 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.c21 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.c22 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.p2 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.c31 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.c32 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.c33 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.p3 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.c41 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
    "        self.c42 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.c43 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.p4 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.c51 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.c52 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.c53 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.p5 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        self.flat = nn.Flatten(1, -1)\n",
    "        self.fc1 = nn.Linear(7*7*512, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.out = nn.Linear(4096, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x - self.RGB_mean[None, :, None, None]\n",
    "        x = self.p1(F.relu(self.c12(F.relu(self.c11(x)))))\n",
    "        x = self.p1(F.relu(self.c22(F.relu(self.c21(x)))))\n",
    "        x = self.p3(F.relu(self.c33(F.relu(self.c32(F.relu(self.c31(x)))))))\n",
    "        x = self.p4(F.relu(self.c43(F.relu(self.c42(F.relu(self.c41(x)))))))\n",
    "        x = self.p5(F.relu(self.c53(F.relu(self.c52(F.relu(self.c51(x)))))))\n",
    "        x = F.relu(self.fc2(F.relu(self.fc1(self.flat(x)))))\n",
    "        Z = self.out(x)\n",
    "\n",
    "\n",
    "        return Z\n",
    "    \n",
    "VGG_model = VGGNet(RGB_mean, 7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGG_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "vgg16 = pickle.load(open('/content/drive/My Drive/vgg_init.sav', 'rb'))\n",
    "params = list(vgg16.parameters())\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    VGG_model.c11.weight = params[0]\n",
    "    VGG_model.c11.bias = params[1]\n",
    "    VGG_model.c12.weight = params[2]\n",
    "    VGG_model.c12.bias = params[3]\n",
    "    \n",
    "    VGG_model.c21.weight = params[4]\n",
    "    VGG_model.c21.bias = params[5]\n",
    "    VGG_model.c22.weight = params[6]\n",
    "    VGG_model.c22.bias = params[7]\n",
    "\n",
    "    VGG_model.c31.weight = params[8]\n",
    "    VGG_model.c31.bias = params[9]\n",
    "    VGG_model.c32.weight = params[10]\n",
    "    VGG_model.c32.bias = params[11]\n",
    "    VGG_model.c33.weight = params[12]\n",
    "    VGG_model.c33.bias = params[13]\n",
    "\n",
    "    VGG_model.c41.weight = params[14]\n",
    "    VGG_model.c41.bias = params[15]\n",
    "    VGG_model.c42.weight = params[16]\n",
    "    VGG_model.c42.bias = params[17]\n",
    "    VGG_model.c43.weight = params[18]\n",
    "    VGG_model.c43.bias = params[19]\n",
    "\n",
    "    VGG_model.c51.weight = params[20]\n",
    "    VGG_model.c51.bias = params[21]\n",
    "    VGG_model.c52.weight = params[22]\n",
    "    VGG_model.c52.bias = params[23]\n",
    "    VGG_model.c53.weight = params[24]\n",
    "    VGG_model.c53.bias = params[25]\n",
    "\n",
    "    VGG_model.fc1.weight = params[26]\n",
    "    VGG_model.fc1.bias = params[27]\n",
    "\n",
    "    VGG_model.fc2.weight = params[28]\n",
    "    VGG_model.fc2.bias = params[29]\n",
    "\n",
    "VGG_model = VGG_model.to(device)\n",
    "old_loss = np.inf\n",
    "\n",
    "max_epoch = 100\n",
    "losses = []\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in trainloader:\n",
    "        \n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        y_hat = VGG_model(X)\n",
    "        \n",
    "        # Calculate Loss (Cross Entropy)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()*len(X)/train_size\n",
    "    \n",
    "    print('Epoch', epoch+1, ': Loss =', running_loss, abs(running_loss-old_loss)/running_loss)\n",
    "    losses.append(running_loss)\n",
    "\n",
    "    if abs(running_loss-old_loss)/running_loss < 1e-2 and running_loss<0.05:\n",
    "        print('Converged')\n",
    "        break\n",
    "    \n",
    "    old_loss = running_loss\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iter Number')\n",
    "plt.title('Convergence monitor plot')\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    y_train = []\n",
    "    y_train_pred = []\n",
    "\n",
    "    for data in trainloader:\n",
    "\n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        y_hat = VGG_model(X)\n",
    "        train_loss += criterion(y_hat, y)*len(X)/train_size\n",
    "        \n",
    "        y_train.extend(list(y.detach().cpu().numpy()))\n",
    "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).detach().cpu().numpy()))\n",
    "\n",
    "print('Train Loss =', train_loss.item())\n",
    "pd.DataFrame(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "''' the confusion matrix gives you insight into how well your classification model is performing.\n",
    "\n",
    "7x7 because there are 7 classes (0-6)\n",
    "The numbers in the diagonal represent the number of correct predictions for each class. \n",
    "There are 43 instances of class 0 correctly classified as class 0,\n",
    "36 instances of class 1 correctly classified as class 1, and so on.\n",
    "Off-diagonal elements represent misclassifications. \n",
    "For example, there are no instances of class 0 mistakenly classified as class 1, class 2, class 3, etc. \n",
    "Hence, all the values in the first row except for the diagonal element are 0.\n",
    "The sum of each row represents the total number of instances for each predicted class, \n",
    "while the sum of each column represents the total number of instances for each actual class.\n",
    "\n",
    "0\t1\t2\t3\t4\t5\t6\n",
    "0\t43\t0\t0\t0\t0\t0\t0\n",
    "1\t0\t36\t0\t0\t0\t0\t0\n",
    "2\t0\t0\t46\t0\t0\t0\t0\n",
    "3\t0\t0\t0\t37\t0\t0\t0\n",
    "4\t0\t0\t0\t0\t40\t0\t0\n",
    "5\t0\t0\t0\t0\t0\t42\t0\n",
    "6\t0\t0\t0\t0\t0\t0\t43\n",
    "'''\n",
    "acc_tr = accuracy_score(y_train, y_train_pred)\n",
    "prec_tr = precision_score(y_train, y_train_pred, average='weighted')\n",
    "f1_tr = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\n",
    "    'Train Accuracy =', acc_tr, 'Train Precision =', prec_tr, 'Train F1 =', f1_tr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
